<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Haoxiang Ma (马浩翔)</title>

    <meta name="author" content="Haoxiang Ma 马浩翔">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p class="name" style="text-align: center;">
                            Haoxiang Ma
                        </p>
                        <p>I'm a PhD student in Beihang University where I focus on 6-DoF Grasping and Robotic Manipulation.
                        </p>
                        <p style="text-align:center">
                            <a href="mahaoxiang822@buaa.edu.cn">Email</a> &nbsp;/&nbsp;
                            <a href="https://scholar.google.com/citations?user=RC0U_o0AAAAJ">Scholar</a> &nbsp;/&nbsp;
                            <a href="https://github.com/mahaoxiang822/">Github</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:37%;max-width:37%">
                        <a href="images/haoxiang.jpg"><img
                                style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                                alt="profile photo" src="images/haoxiang.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:16px;width:100%;vertical-align:middle">
                        <h2>Research</h2>
                        <p>
                            I'm interested in robotic learning, computer vision and embodied AI. Most
                            of my research is about inferring the grasp poses from
                            images and point-clouds.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='active_grasp_image'>
                                <img src='images/active_grasp.png' width="100%"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/ActiveNGF">
          <span class="papertitle">Active Perception for Grasp Detection via Neural Graspness Field</span>
                        </a>
                        <br>
                        <strong>Haoxiang Ma</strong>,
                        <a>Modi Shi</a>,
                        <a>Boyang Gao</a>,
                        <a>Di Huang</a>
                        <br>
                        <em>NeurIPS</em>, 2024
                        <br>
<!--                        <a href="https://github.com/mahaoxiang822/ActiveNGF">code</a>-->
<!--                        /-->
                        <a href="https://openreview.net/pdf?id=6FYh6gxzPf">paper</a>
                        <p></p>
                        <p>
                            An active perception method for grasp detection by introducing the neural graspness field, which models the grasp distribution of a scene.
                        </p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='gen_grasp_image'>
                                <img src='images/gen_grasp.png' width="160"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/Generalizing-Grasp">
          <span class="papertitle">Generalizing 6-DoF Grasp Detection via Domain Prior Knowledge</span>
                        </a>
                        <br>
                        <strong>Haoxiang Ma</strong>,
                        <a>Modi Shi</a>,
                        <a>Boyang Gao</a>,
                        <a>Di Huang</a>
                        <br>
                        <em>CVPR</em>, 2024
                        <br>
                        <a href="https://github.com/mahaoxiang822/Generalizing-Grasp">code</a>
                        /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Generalizing_6-DoF_Grasp_Detection_via_Domain_Prior_Knowledge_CVPR_2024_paper.pdf">paper</a>
                        /
                        <a href="https://www.youtube.com/watch?v=RzTXFcZURiU&t=14s">video</a>

                        <p>
                             Generalizing 6-DoF grasp detection framework with domain prior knowledge of robotic grasping.
                        </p>
                    </td>
                </tr>


                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='s2r_grasp'>
                                <img src='images/s2r_grasp.png' width="160"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/GL-MSDA">
          <span class="papertitle">Sim-to-Real Grasp Detection with Global-to-Local RGB-D Adaptation</span>
                        </a>
                        <br>
                        <strong>Haoxiang Ma</strong>,
                        <a>Ran Qin</a>,
                        <a>Modi Shi</a>,
                        <a>Boyang Gao</a>,
                        <a>Di Huang</a>
                        <br>
                        <em>ICRA</em>, 2024
                        <br>
                        <a href="https://github.com/mahaoxiang822/GL-MSDA">code</a>
                        /
                        <a href="https://arxiv.org/pdf/2403.11511">paper</a>
                        <p>
                             We present a global-to-local method to address hybrid domain gaps in RGB and depth data and insufficient multi-modal feature alignment.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='dgcan'>
                                <img src='images/dgcan.png' width="160"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/dgcan">
          <span class="papertitle">Sim-to-Real Grasp Detection with Global-to-Local RGB-D Adaptation</span>
                        </a>
                        <br>
                        <a>Ran Qin</a>,
                        <strong>Haoxiang Ma</strong>,
                        <a>Boyang Gao</a>,
                        <a>Di Huang</a>
                        <br>
                        <em>ICRA</em>, 2023
                        <br>
                        <a href="https://github.com/mahaoxiang822/dgcan">code</a>
                        /
                        <a href="https://arxiv.org/pdf/2302.14264">paper</a>
                        <p>
                             We build a depth guided learning framework, where both the RGB and depth images are fed and their features are combined to generate grasp proposals.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='sbl'>
                                <img src='images/sbl.png' width="160"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/Scale-Balanced-Grasp">
          <span class="papertitle">Generalizing 6-DoF Grasp Detection via Domain Prior Knowledge</span>
                        </a>
                        <br>
                        <strong>Haoxiang Ma</strong>,
                        <a>Di Huang</a>
                        <br>
                        <em>CoRL</em>, 2022
                        <br>
                        <a href="https://github.com/mahaoxiang822/Scale-Balanced-Grasp">code</a>
                        /
                        <a href="https://openreview.net/pdf?id=tiPHpS4eA4">paper</a>
                        /
                        <a href="https://www.youtube.com/watch?v=EUXYsd5gK8I">video</a>
                        <p>
                              Focus on the problem of feature learning in the presence of scale imbalance for 6-DoF grasp detection and propose a novel approach to especially address the difficulty in dealing with small-scale samples.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:16px;width:20%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='bcanet'>
                                <img src='images/bcanet.png' width="160"></div>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:middle">
                        <a href="https://github.com/mahaoxiang822/Boundary-Guided-Context-Aggregation">
          <span class="papertitle">Boundary Guided Context Aggregation for Semantic Segmentation</span>
                        </a>
                        <br>
                        <strong>Haoxiang Ma</strong>,
                        <a>Hongyu Yang</a>,
                        <a>Di Huang</a>
                        <br>
                        <em>BMVC</em>, 2021
                        <br>
                        <a href="https://github.com/mahaoxiang822/Boundary-Guided-Context-Aggregation">code</a>
                        /
                        <a href="https://arxiv.org/pdf/2110.14587">paper</a>
                        <p>
                             We exploit boundary as a significant guidance for context aggregation to promote the overall semantic understanding of an image.
                        </p>
                    </td>
                </tr>

                </tbody>
            </table>


            <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;">
                <tbody>
                <tr>
                    <td>
                        <h2>Miscellanea</h2>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <tr>
                    <td align="center" style="padding:16px;width:20%;vertical-align:middle">
                        <div class="colored-box" style="background-color: #c6b89e;">
                            <h2>Academic Service</h2>
                        </div>
                    </td>
                    <td style="padding:8px;width:80%;vertical-align:center">
                        <p>Reviewer of CVPR, CoRL, ICLR, NeurIPS, ICML, RA-L and etc.</p>

                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://github.com/jonbarron/jonbarron_website">Website template from Jon Barron</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>
</html>
